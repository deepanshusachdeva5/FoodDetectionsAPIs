{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1bdaa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 2200\n",
      "Number of unique movieId's: 256\n",
      "Number of unique users: 20\n",
      "Average ratings per user: 110.0\n",
      "Average ratings per movie: 8.59\n",
      "Since you ate Boiled-egg\n",
      "Tandoori Fish Tikka\n",
      "Masor Koni\n",
      "Gulab jamun\n",
      "Bebinca\n",
      "Mysore pak\n",
      "Kutchi dabeli\n",
      "Dum aloo\n",
      "Bora Sawul\n",
      "Pork Bharta\n",
      "Upma\n"
     ]
    }
   ],
   "source": [
    "# code\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import warnings\n",
    "\n",
    "\n",
    "def get_ratings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "    ratings = pd.read_csv(\"Ratings.csv\")\n",
    "    #ratings.head()\n",
    "\n",
    "    movies = pd.read_csv(\"indian_food.csv\")\n",
    "    #movies.head()\n",
    "\n",
    "    n_ratings = len(ratings)\n",
    "    n_movies = len(ratings['Food_Id'].unique())\n",
    "    n_users = len(ratings['User_Id'].unique())\n",
    "\n",
    "    print(f\"Number of ratings: {n_ratings}\")\n",
    "    print(f\"Number of unique movieId's: {n_movies}\")\n",
    "    print(f\"Number of unique users: {n_users}\")\n",
    "    print(f\"Average ratings per user: {round(n_ratings/n_users, 2)}\")\n",
    "    print(f\"Average ratings per movie: {round(n_ratings/n_movies, 2)}\")\n",
    "\n",
    "    user_freq = ratings[['User_Id', 'Food_Id']].groupby('User_Id').count().reset_index()\n",
    "    user_freq.columns = ['User_Id', 'Ratings']\n",
    "    #user_freq.head()\n",
    "\n",
    "\n",
    "    # Find Lowest and Highest rated movies:\n",
    "    mean_rating = ratings.groupby('Food_Id')[['Ratings']].mean()\n",
    "    # Lowest rated movies\n",
    "    lowest_rated = mean_rating['Ratings'].idxmin()\n",
    "    movies.loc[movies['Id'] == lowest_rated]\n",
    "    # Highest rated moviess\n",
    "    highest_rated = mean_rating['Ratings'].idxmax()\n",
    "    movies.loc[movies['Id'] == highest_rated]\n",
    "    # show number of people who rated movies rated movie highest\n",
    "    ratings[ratings['Food_Id']==highest_rated]\n",
    "    # show number of people who rated movies rated movie lowest\n",
    "    ratings[ratings['Food_Id']==lowest_rated]\n",
    "\n",
    "    ## the above movies has very low dataset. We will use bayesian average\n",
    "    movie_stats = ratings.groupby('Food_Id')[['Ratings']].agg(['count', 'mean'])\n",
    "    movie_stats.columns = movie_stats.columns.droplevel()\n",
    "    return ratings,movies\n",
    "\n",
    "# Now, we create user-item matrix using scipy csr matrix\n",
    "\n",
    "\n",
    "def create_matrix(df):\n",
    "\t\n",
    "\tN = len(df['User_Id'].unique())\n",
    "\tM = len(df['Food_Id'].unique())\n",
    "\t\n",
    "\t# Map Ids to indices\n",
    "\tuser_mapper = dict(zip(np.unique(df[\"User_Id\"]), list(range(N))))\n",
    "\tmovie_mapper = dict(zip(np.unique(df[\"Food_Id\"]), list(range(M))))\n",
    "\t\n",
    "\t# Map indices to IDs\n",
    "\tuser_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"User_Id\"])))\n",
    "\tmovie_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"Food_Id\"])))\n",
    "\t\n",
    "\tuser_index = [user_mapper[i] for i in df['User_Id']]\n",
    "\tmovie_index = [movie_mapper[i] for i in df['Food_Id']]\n",
    "\n",
    "\tX = csr_matrix((df[\"Ratings\"], (movie_index, user_index)), shape=(M, N))\n",
    "\t\n",
    "\treturn X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Find similar movies using KNN\n",
    "\"\"\"\n",
    "def find_similar_movies(movie_id, movie_mapper,movie_inv_mapper,X, k, metric='cosine', show_distance=False):\n",
    "\t\n",
    "\tneighbour_ids = []\n",
    "\t\n",
    "\tmovie_ind = movie_mapper[movie_id]\n",
    "\tmovie_vec = X[movie_ind]\n",
    "\tk+=1\n",
    "\tkNN = NearestNeighbors(n_neighbors=k, algorithm=\"brute\", metric=metric)\n",
    "\tkNN.fit(X)\n",
    "\tmovie_vec = movie_vec.reshape(1,-1)\n",
    "\tneighbour = kNN.kneighbors(movie_vec, return_distance=show_distance)\n",
    "\tfor i in range(0,k):\n",
    "\t\tn = neighbour.item(i)\n",
    "\t\tneighbour_ids.append(movie_inv_mapper[n])\n",
    "\tneighbour_ids.pop(0)\n",
    "\treturn neighbour_ids\n",
    "\n",
    "\n",
    "def get_recommendations():\n",
    "    ratings, movies = get_ratings()\n",
    "    X, user_mapper, movie_mapper, user_inv_mapper, movie_inv_mapper = create_matrix(ratings)\n",
    "    movie_titles = dict(zip(movies['Id'], movies['name']))\n",
    "\n",
    "    movie_id = 256\n",
    "\n",
    "    similar_ids = find_similar_movies(movie_id, movie_mapper,movie_inv_mapper,X, k=10)\n",
    "    movie_title = movie_titles[movie_id]\n",
    "\n",
    "    print(f\"Since you ate {movie_title}\")\n",
    "    for i in similar_ids:\n",
    "        print(movie_titles[i])\n",
    "        \n",
    "get_recommendations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a0bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
